% klucove clanky:

% A review of object detection based on deep learning, Youzi Xiao https://link.springer.com/content/pdf/10.1007/s11042-020-08976-6.pdf

% 01 - OVERVIEW

@book{ANN,
publisher = {Springer International Publishing},
isbn = {3-319-28493-2},
year = {2016},
title = {Artificial Neural Network Modelling},
language = {eng},
author = {Subana Shanmuganathan, Sandhya Samarasinghe},
}


@article{lee2004driving,
  title={Driving performance in the Presence and absence of billboards},
  author={Lee, Suzanne E and Olsen, Erik CB and DeHart, Maryanne C},
  year={2004}
}


@inproceedings{tarnowski2017roadside,
  title={Roadside advertising and the distraction of driver’s attention},
  author={Tarnowski, Adam and Olejniczak-Serowiec, Anna and Marszalec, Agnieszka},
  booktitle={MATEC Web of Conferences},
  volume={122},
  pages={03010},
  year={2017},
  organization={EDP Sciences}
}

@article{marciano2017effect,
  title={The effect of billboard design specifications on driving: a pilot study},
  author={Marciano, Hadas and others},
  journal={Accident Analysis \& Prevention},
  volume={104},
  pages={174--184},
  year={2017},
  publisher={Elsevier}
}


@article{horberry200813,
  title={13 Distractions outside the Vehicle},
  author={Horberry, Tim and Edquist, Jessica},
  journal={Driver distraction: Theory, effects, and mitigation},
  pages={215},
  year={2008},
  publisher={CRC Press}
}


@article{harasimczuk2021longer,
  title={Are longer advertising slogans more dangerous? The influence of the length of ad slogans on drivers’ attention and motor behavior},
  author={Harasimczuk, Justyna and Maliszewski, Norbert E and Olejniczak-Serowiec, Anna and Tarnowski, Adam},
  journal={Current Psychology},
  volume={40},
  pages={429--441},
  year={2021},
  publisher={Springer}
}


@article{chan2013emotional,
  title={The emotional side of cognitive distraction: Implications for road safety},
  author={Chan, Michelle and Singhal, Anthony},
  journal={Accident Analysis \& Prevention},
  volume={50},
  pages={147--154},
  year={2013},
  publisher={Elsevier}
}

@article{MaliszewskiNorbert2019Iosa,
issn = {1932-6203},
abstract = {Sexual appeals are widely used in advertising to attract consumers' attention. It has already been proved that they influence the addressee's cognitive processing, which in turn raises the question if sexual appeals may pose a serious threat for road safety when used in roadside advertising. Three studies were designed to answer this question. Study I was a nationwide survey (N = 1095) which revealed that drivers subjectively perceive sexual contents in roadside advertising as distracting and dangerous. Study II was a modified version of the Attentional Network Test (N = 1063) which proved that in cognitive tasks reaction time increases in line with the sexual content of advertisements. Study III was a simulator study (N = 55) which confirmed that driving characteristics change when sexually-oriented advertisements are located along the road. These studies have led us to a conclusion that sexually appealing cues in roadside advertising may pose a threat for road safety.},
journal = {PloS one},
pages = {e0216919--e0216919},
volume = {14},
publisher = {Public Library of Science},
number = {5},
year = {2019},
title = {Influence of sexual appeal in roadside advertising on drivers' attention and driving behavior},
copyright = {COPYRIGHT 2019 Public Library of Science},
language = {eng},
address = {United States},
author = {Maliszewski, Norbert and Olejniczak-Serowiec, Anna and Harasimczuk, Justyna},
keywords = {Adolescent ; Adult ; Advertising ; Aged ; Aged, 80 and over ; Attention ; Automobile drivers ; Automobile Driving ; Behavior ; Biology and Life Sciences ; Cognition ; Cognition \& reasoning ; Cognitive ability ; Cognitive tasks ; Driver behavior ; Drivers ; Engineering and Technology ; Female ; Humans ; Influence ; Information processing ; Male ; Medicine and Health Sciences ; Middle Aged ; Reaction Time ; Roads ; Safety ; Sexual attraction ; Sexual behavior ; Social Sciences ; Studies ; Traffic accidents \& safety},
}


@article{meuleners2020identifying,
  title={Identifying the distracting aspects of electronic advertising billboards: A driving simulation study},
  author={Meuleners, Lynn and Roberts, Paul and Fraser, Michelle},
  journal={Accident Analysis \& Prevention},
  volume={145},
  pages={105710},
  year={2020},
  publisher={Elsevier}
}

@article{megias2011modulation,
  title={Modulation of attention and urgent decisions by affect-laden roadside advertisement in risky driving scenarios},
  author={Meg{\'\i}as, Alberto and Maldonado, Antonio and Catena, Andr{\'e}s and Di Stasi, Leandro L and Serrano, Jes{\'u}s and C{\'a}ndido, Antonio},
  journal={Safety Science},
  volume={49},
  number={10},
  pages={1388--1393},
  year={2011},
  publisher={Elsevier}
}


@article{EDQUIST2011619,
title = {Effects of advertising billboards during simulated driving},
journal = {Applied Ergonomics},
volume = {42},
number = {4},
pages = {619-626},
year = {2011},
note = {Applied Ergonomics and Transportation Safety},
issn = {0003-6870},
doi = {https://doi.org/10.1016/j.apergo.2010.08.013},
url = {https://www.sciencedirect.com/science/article/pii/S0003687010001274},
author = {Jessica Edquist and Tim Horberry and Simon Hosking and Ian Johnston},
keywords = {Distraction, Roadside advertising, Driving simulation, Lane change test, Response time, Eye movements},
abstract = {There is currently a great deal of interest in the problem of driver distraction. Most research focuses on distractions from inside the vehicle, but drivers can also be distracted by objects outside the vehicle. Major roads are increasingly becoming sites for advertising billboards, and there is little research on the potential effects of this advertising on driving performance. The driving simulator experiment presented here examines the effects of billboards on drivers, including older and inexperienced drivers who may be more vulnerable to distractions. The presence of billboards changed drivers’ patterns of visual attention, increased the amount of time needed for drivers to respond to road signs, and increased the number of errors in this driving task.}
}

@article{belyusar2016field,
  title={A field study on the effects of digital billboards on glance behavior during highway driving},
  author={Belyusar, Daniel and Reimer, Bryan and Mehler, Bruce and Coughlin, Joseph F},
  journal={Accident Analysis \& Prevention},
  volume={88},
  pages={88--96},
  year={2016},
  publisher={Elsevier}
}

@article{stavrinos2016visual,
  title={Visual behavior differences in drivers across the lifespan: A digital billboard simulator study},
  author={Stavrinos, Despina and Mosley, Peyton R and Wittig, Shannon M and Johnson, Haley D and Decker, John S and Sisiopiku, Virginia P and Welburn, Sharon C},
  journal={Transportation research part F: traffic psychology and behaviour},
  volume={41},
  pages={19--28},
  year={2016},
  publisher={Elsevier}
}


@article{crundall,
  title={Attraction and distraction of attention with roadside advertisements},
  author={Crundall, David and Van Loon, Editha and Underwood, Geoffrey},
  journal={Accident Analysis \& Prevention},
  volume={38},
  number={4},
  pages={671--677},
  year={2006},
  publisher={Elsevier}
}

@article{zalesinska2018impact,
  title={The impact of the luminance, size and location of LED billboards on drivers’ visual performance—laboratory tests},
  author={Zalesinska, Malgorzata},
  journal={Accident Analysis \& Prevention},
  volume={117},
  pages={439--448},
  year={2018},
  publisher={Elsevier}
}

@article{mollu2018driving,
  title={Driving simulator study on the influence of digital illuminated billboards near pedestrian crossings},
  author={Mollu, Kristof and Cornu, Joris and Brijs, Kris and Pirdavani, Ali and Brijs, Tom},
  journal={Transportation research part F: traffic psychology and behaviour},
  volume={59},
  pages={45--56},
  year={2018},
  publisher={Elsevier}
}

@article{costa,
  title={Driver's visual attention to different categories of roadside advertising signs},
  author={Costa, Marco and Bonetti, Leonardo and Vignali, Valeria and Bichicchi, Arianna and Lantieri, Claudio and Simone, Andrea},
  journal={Applied ergonomics},
  volume={78},
  pages={127--136},
  year={2019},
  publisher={Elsevier}
}

@Article{cz,
AUTHOR = {Nouzovský, Luboš and Vrtal, Pavel and Kohout, Tomáš and Svatý, Zdeněk},
TITLE = {Using the Eye Tracking Method to Determine the Risk of Advertising Devices on Drivers},
JOURNAL = {Applied Sciences},
VOLUME = {12},
YEAR = {2022},
NUMBER = {13},
ARTICLE-NUMBER = {6795},
URL = {https://www.mdpi.com/2076-3417/12/13/6795},
ISSN = {2076-3417},
DOI = {10.3390/app12136795}
}




@article{n1,
title = {Effects of advertising billboards during simulated driving},
journal = {Applied Ergonomics},
volume = {42},
number = {4},
pages = {619-626},
year = {2011},
note = {Applied Ergonomics and Transportation Safety},
issn = {0003-6870},
doi = {https://doi.org/10.1016/j.apergo.2010.08.013},
url = {https://www.sciencedirect.com/science/article/pii/S0003687010001274},
author = {Jessica Edquist and Tim Horberry and Simon Hosking and Ian Johnston},
keywords = {Distraction, Roadside advertising, Driving simulation, Lane change test, Response time, Eye movements},
abstract = {There is currently a great deal of interest in the problem of driver distraction. Most research focuses on distractions from inside the vehicle, but drivers can also be distracted by objects outside the vehicle. Major roads are increasingly becoming sites for advertising billboards, and there is little research on the potential effects of this advertising on driving performance. The driving simulator experiment presented here examines the effects of billboards on drivers, including older and inexperienced drivers who may be more vulnerable to distractions. The presence of billboards changed drivers’ patterns of visual attention, increased the amount of time needed for drivers to respond to road signs, and increased the number of errors in this driving task.}
}

@article{OVIEDOTRESPALACIOS201985,
title = {The impact of road advertising signs on driver behaviour and implications for road safety: A critical systematic review},
journal = {Transportation Research Part A: Policy and Practice},
volume = {122},
pages = {85-98},
year = {2019},
issn = {0965-8564},
doi = {https://doi.org/10.1016/j.tra.2019.01.012},
url = {https://www.sciencedirect.com/science/article/pii/S0965856418310632},
author = {Oscar Oviedo-Trespalacios and Verity Truelove and Barry Watson and Jane A. Hinton},
keywords = {Billboards, Ergonomics, Driver behaviour, Distraction, Road design, Driving environment, Human factors},
abstract = {Driver inattention and distraction are recognised as two of the most critical factors for road safety worldwide. While roadside advertising is often identified as a potential source of distraction, it has received less attention compared to other types of distractions such as texting or calling while driving. Therefore, this study focused on the impact of roadside advertising signs on driver behaviour and road safety. To examine this, a theory-driven systematic literature review was undertaken. In total, 90 unique documents were identified and reviewed using the Task-Capability Interface (TCI) Model to explain the potential safety impact of roadside advertising. The findings confirmed that the TCI model is a useful tool for describing the relationship between roadside advertising and driver behaviour. From this perspective, roadside advertising signs can be considered environmental clutter, which adds additional demands to the driving task. In particular, roadside advertising signs impaired eye movement patterns of drivers. Additionally, it was demonstrated that the impact of roadside advertising on driving behaviour is greatly moderated by individual differences among drivers. Of great importance was that young drivers invest more attentional resources in interacting with roadside advertising, which suggests a lower capacity to discriminate between relevant and irrelevant driving information. Based on the available evidence, however, it is not possible to definitively conclude that there is a direct relationship between the driving behaviour changes attributed to roadside advertising and road crashes. Nonetheless, while most studies remain inconclusive, there is an emerging trend in the literature suggesting that roadside advertising can increase crash risk, particularly for those signs that have the capacity to frequently change (often referred to as digital billboards). Lastly, it is important to mention that most of the empirical studies undertaken to date feature strong methodological limitations. Consequently, there is an urgent need for more research in this area, given that roadside technology and the transport system are changing rapidly.}
}

@article{beijer,
  title={Observed driver glance behavior at roadside advertising signs},
  author={Beijer, Daan and Smiley, Alison and Eizenman, Moshe},
  journal={Transportation Research Record},
  volume={1899},
  number={1},
  pages={96--103},
  year={2004},
  publisher={SAGE Publications Sage CA: Los Angeles, CA}
}

@article{brome,
  title={Roadside digital billboard advertisements: Effects of static, transitioning, and animated designs on drivers’ performance and attention},
  author={Brome, Reem and Awad, Mariette and Moacdieh, Nadine Marie},
  journal={Transportation research part F: traffic psychology and behaviour},
  volume={83},
  pages={226--237},
  year={2021},
  publisher={Elsevier}
}

@article{bendak2010role,
  title={The role of roadside advertising signs in distracting drivers},
  author={Bendak, Salaheddine and Al-Saleh, Khalid},
  journal={International Journal of Industrial Ergonomics},
  volume={40},
  number={3},
  pages={233--236},
  year={2010},
  publisher={Elsevier}
}


@article{WF,
title = {Don't wait for accidents — possibilities to assess risk in traffic by applying the ‘Wiener Fahrprobe’},
journal = {Safety Science},
volume = {19},
number = {2},
pages = {137-147},
year = {1995},
note = {Safety of Transportation},
issn = {0925-7535},
doi = {https://doi.org/10.1016/0925-7535(94)00015-U},
url = {https://www.sciencedirect.com/science/article/pii/092575359400015U},
author = {Christine Chaloupka and Ralf Risser},
abstract = {In Vienna during more than 10 years of research work a special traffic behaviour observation method has been developed, evaluated and applied by Risser et al. in the frame of many different traffic safety projects. Car drivers are accompanied by two observers who register not only errors in behaviour of drivers but also their communication and interaction with other road users. Malfunction of communication and interaction are judged as main sources for problems for danger in traffic. For example, if they lead to a bad traffic climate fealings of discomfort, anger and frustration will prevent cooperative actions of road users. Being able to recognize such negative or dangerous interaction patterns in time it seems to be easier to protect road users — most often the ‘unprotected’ ones — from getting involved in accidents. This contribution gives an impression about theory and practice of the observation method and shows results of different studies, where the method called ‘Wiener Fahrprobe’ has been applied. Furthermore it will show how the method and its results can be used in the frame of the European traffic (safety) research projects ‘PROMETHEUS’ and ‘DRIVE’. Till now no accident data exist in respect to new RTI systems. Therefore it seems to be important to have a sophisticated social-psychological method for testing the behaviour and interaction of road users in connection with these systems. This is a necessary prediction for deciding whether the systems are socially compatible or not.}
}

@inproceedings{CV-vs-DL,
  title={Deep learning vs. traditional computer vision},
  author={O’Mahony, Niall and Campbell, Sean and Carvalho, Anderson and Harapanahalli, Suman and Hernandez, Gustavo Velasco and Krpalkova, Lenka and Riordan, Daniel and Walsh, Joseph},
  booktitle={Science and information conference},
  pages={128--144},
  year={2019},
  organization={Springer}
}

@InProceedings{sel-search,
  author       = "van de Sande, K. E. A. and Uijlings, J. R. R. and Gevers, T. and Smeulders, A. W. M.",
  title        = "Segmentation As Selective Search for Object Recognition",
  booktitle    = "IEEE International Conference on Computer Vision",
  year         = "2011"
}

@INPROCEEDINGS{HOG,  author={Dalal, N. and Triggs, B.},  booktitle={2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)},   title={Histograms of oriented gradients for human detection},   year={2005},  volume={1},  number={},  pages={886-893 vol. 1},  doi={10.1109/CVPR.2005.177}}

@article{SIFT,
  title={Distinctive Image Features from Scale-Invariant Keypoints},
  author={G LoweDavid},
  journal={International Journal of Computer Vision},
  year={2004}
}

@inproceedings{SURF,
author = {Bay, Herbert and Tuytelaars, Tinne and Van Gool, Luc},
year = {2006},
month = {01},
pages = {404-417},
title = {SURF: Speeded Up Robust Features.},
volume = {110},
journal = {Computer Vision and Image Understanding - CVIU}
}

@article{SVN,
  title={Support-Vector Networks},
  author={Corinna Cortes and Vladimir Naumovich Vapnik},
  journal={Machine Learning},
  year={2004},
  volume={20},
  pages={273-297}
}

@INPROCEEDINGS{Adaboost,  author={Viola, P. and Jones, M.},  booktitle={Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001},   title={Rapid object detection using a boosted cascade of simple features},   year={2001},  volume={1},  number={},  pages={I-I},  doi={10.1109/CVPR.2001.990517}}

@Inbook{Itti,
author="Koch, Christof
and Ullman, Shimon",
editor="Vaina, Lucia M.",
title="Shifts in Selective Visual Attention: Towards the Underlying Neural Circuitry",
bookTitle="Matters of Intelligence: Conceptual Structures in Cognitive Neuroscience",
year="1987",
publisher="Springer Netherlands"
}

% podobné práce 1

@thesis{DP0,
author="Zrubec, Michal",
title="Detekcia vizuálneho smogu pri cestách",
year="2021",
publisher="CRZP"
}

@incollection{old,
  title={A neural Network for symmetry-based object detection and tracking},
  author={Kalinke, Thomas and Seelen, Werner von},
  booktitle={Mustererkennung 1996},
  pages={37--44},
  year={1996},
  publisher={Springer}
}


@article{Hossari,
author = {Hossari, Murhaf and Dev, Soumyabrata and Nicholson, Matthew and McCabe, Killian and Nautiyal, Atul and Conran, Clare and Tang, Jian and Xu, Wei and Pitié, François},
year = {2018},
month = {11},
pages = {},
title = {ADNet: A Deep Network for Detecting Adverts}
}

@article{SSD-YOLO,
author = {Morera, Angel and Sanchez, Angel and Moreno, A.B. and Sappa, Angel and Vélez, Jose},
year = {2020},
month = {08},
pages = {4587},
title = {SSD vs. YOLO for Detection of Outdoor Urban Advertising Panels under Multiple Variabilities},
volume = {20},
journal = {Sensors},
doi = {10.3390/s20164587}
}

@article{GeoTag,
  title={Advertisement billboard detection and geotagging system with inductive transfer learning in deep convolutional neural network},
  author={Romi Fadillah Rahmat and Dennis Dennis and Opim Salim Sitompul and Sarah Purnamawati and Rahmat Budiarto},
  journal={TELKOMNIKA (Telecommunication Computing Electronics and Control)},
  year={2019}
}

@article{Mapillary,
  title={The Mapillary Vistas Dataset for Semantic Understanding of Street Scenes},
  author={Gerhard Neuhold and Tobias Ollmann and Samuel Rota Bul{\`o} and Peter Kontschieder},
  journal={2017 IEEE International Conference on Computer Vision (ICCV)},
  year={2017},
  pages={5000-5009}
}

@InProceedings{Coco,
author="Lin, Tsung-Yi
and Maire, Michael
and Belongie, Serge
and Hays, James
and Perona, Pietro
and Ramanan, Deva
and Doll{\'a}r, Piotr
and Zitnick, C. Lawrence",
editor="Fleet, David
and Pajdla, Tomas
and Schiele, Bernt
and Tuytelaars, Tinne",
title="Microsoft COCO: Common Objects in Context",
booktitle="Computer Vision -- ECCV 2014",
year="2014",
publisher="Springer International Publishing",
}

@article{SVM,
  title={Support vector machines},
  author={Hearst, Marti A. and Dumais, Susan T and Osuna, Edgar and Platt, John and Scholkopf, Bernhard},
  journal={IEEE Intelligent Systems and their applications},
  volume={13},
  number={4},
  pages={18--28},
  year={1998},
  publisher={IEEE}
}

@article{PVD,
issn = {1424-8220},
journal = {Sensors (Basel, Switzerland)},
pages = {7267},
volume = {21},
publisher = {MDPI AG},
number = {21},
year = {2021},
title = {Pedestrian and Vehicle Detection in Autonomous Vehicle Perception Systems—A Review},
copyright = {2021 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License.},
language = {eng},
address = {Basel},
author = {Galvao, Luiz G. and Abbod, Maysam and Kalganova, Tatiana and Palade, Vasile and Huda, Md Nazmul},
keywords = {Algorithms ; Automation ; autonomous vehicle ; Autonomous vehicles ; Computer vision ; Datasets ; deep learning ; Fatalities},
}

@article{TSD,
issn = {1002-137X},
journal = {Ji suan ji ke xue},
pages = {89},
volume = {48},
publisher = {Guojia Kexue Jishu Bu},
number = {1},
year = {2021},
title = {L-YOLO:Real Time Traffic Sign Detection Model for Vehicle Edge Computing},
copyright = {Copyright Guojia Kexue Jishu Bu 2021},
language = {chi},
address = {Chongqing},
author = {Shan, Mei-Jing and Qin, Long-Fei and Zhang, Hui-Bing},
keywords = {Algorithms ; Edge computing ; Lightweight ; Real time ; Street signs ; Traffic control ; Traffic models ; Traffic signs},
}

@article{VOD,
issn = {0045-7906},
journal = {Computers \& electrical engineering},
pages = {107406},
volume = {95},
publisher = {Elsevier Ltd},
year = {2021},
title = {Vehicle detection from road image sequences for intelligent traffic scheduling},
copyright = {2021 Elsevier Ltd},
language = {eng},
address = {Amsterdam},
author = {Li, Yaochen and Chen, Yuting and Yuan, Sheng and Liu, Jingle and Zhao, Xi and Yang, Yang and Liu, Yuehu},
keywords = {Algorithms ; Asymmetric convolution ; Context ; Deep reinforcement learning ; Feature extraction ; Global context attention ; Intelligent transportation ; Machine learning ; Object recognition ; Scheduling ; Small object detection ; Traffic congestion ; Traffic control ; Traffic flow ; Traffic models ; Traffic signals ; Unmanned aerial vehicles},
}

@misc{MIT300,
  author     = {Zoya Bylinskii and Tilke Judd and Ali Borji and Laurent Itti and Fr{\'e}do Durand and Aude Oliva and Antonio Torralba},
  title      = {MIT Saliency Benchmark},
}

@InProceedings{SALICON,
author = {Jiang, Ming and Huang, Shengsheng and Duan, Juanyong and Zhao, Qi},
title = {SALICON: Saliency in Context},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2015}
}

@inproceedings{FSM,
author = {Vig, Eleonora and Dorr, Michael and Cox, David},
year = {2014},
month = {06},
pages = {2798-2805},
title = {Large-Scale Optimization of Hierarchical Features for Saliency Prediction in Natural Images},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2014.358}
}

@incollection{UniSal,
series = {Lecture Notes in Computer Science},
issn = {0302-9743},
pages = {419--435},
publisher = {Springer International Publishing},
booktitle = {Computer Vision – ECCV 2020},
isbn = {3030585573},
year = {2020},
title = {Unified Image and Video Saliency Modeling},
copyright = {Springer Nature Switzerland AG 2020},
language = {eng},
address = {Cham},
author = {Droste, Richard and Jiao, Jianbo and Noble, J. Alison},
keywords = {Ablation ; Benchmarks ; Coders ; Computer vision ; Datasets ; Domain adaptation ; Domains ; Modelling ; Salience ; Video data ; Video saliency ; Visual saliency},
}

@inproceedings{ViNet,
issn = {2153-0866},
pages = {3520--3527},
publisher = {IEEE},
booktitle = {2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
isbn = {1665417145},
year = {2021},
title = {ViNet: Pushing the limits of Visual Modality for Audio-Visual Saliency Prediction},
language = {eng},
author = {Jain, Samyak and Yarlagadda, Pradeep and Jyoti, Shreyank and Karthik, Shyamgopal and Subramanian, Ramanathan and Gandhi, Vineet},
keywords = {Convolutional codes ; Decoding ; Predictive models ; Real-time systems ; Three-dimensional displays ; Training ; Visualization},
}


@article{TranSalNet,
issn = {0925-2312},
journal = {Neurocomputing (Amsterdam)},
pages = {455--467},
volume = {494},
publisher = {Elsevier B.V},
year = {2022},
title = {TranSalNet: Towards perceptually relevant visual saliency prediction},
copyright = {2022 The Authors},
language = {eng},
address = {Ithaca},
author = {Lou, Jianxun and Lin, Hanhe and Marshall, David and Saupe, Dietmar and Liu, Hantao},
keywords = {Analysis ; Artificial neural networks ; Computer science ; Convolutional neural network ; Deep learning ; Information science ; Neural networks ; Salience ; Saliency prediction ; Transformer ; Transformers},
}


% podobné práce 2

@misc{FoA,
  doi = {10.48550/ARXIV.1705.03854},
  url = {https://arxiv.org/abs/1705.03854},
  author = {Palazzi, Andrea and Abati, Davide and Calderara, Simone and Solera, Francesco and Cucchiara, Rita},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Predicting the Driver's Focus of Attention: the DR(eye)VE Project},
  publisher = {arXiv},
  year = {2017},  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{BDDA,
series = {Lecture Notes in Computer Science},
issn = {0302-9743},
pages = {658--674},
publisher = {Springer International Publishing},
booktitle = {Computer Vision – ACCV 2018},
isbn = {3030208729},
year = {2019},
title = {Predicting Driver Attention in Critical Situations},
copyright = {Springer Nature Switzerland AG 2019},
language = {eng},
address = {Cham},
author = {Xia, Ye and Zhang, Danqing and Kim, Jinkyu and Nakayama, Ken and Zipser, Karl and Whitney, David},
keywords = {BDD-A dataset ; Berkeley DeepDrive ; Driver attention prediction},
}

@online{grad,
  author = {David Mata},
  title = {Stochastic Gradient Descent – Python},
  year = {2017},
  url = {https://davidmatablog.wordpress.com/2017/10/26/stochastic-gradient-descent-python/},
  urldate = {2023-02-28}
}

@online{SF,
  author = {Fei-Fei Li, Yunzhu Li, Ruohan Gao},
  title = {CS231n: Deep Learning for Computer Vision},
  year = {2023},
  url = {http://cs231n.stanford.edu/slides/},
  urldate = {2023-02-07}
}

@online{filters,
  author = {Prakhar Ganesh},
  title = {Types of Convolution Kernels : Simplified},
  year = {2019},
  url = {https://towardsdatascience.com/types-of-convolution-kernels-simplified-f040cb307c37},
  urldate = {2023-04-13}
}

@online{pool,
  author = {Neznámy autor},
  title = {Explain Pooling layers: Max Pooling, Average Pooling, Global Average Pooling, and Global Max pooling},
  year = {2021},
  url = {https://androidkt.com/explain-pooling-layers-max-pooling-average-pooling-global-average-pooling-and-global-max-pooling/},
  urldate = {2023-04-13}
}

@online{googlemaps,
  author = {Ján Špirka},
  title = {Trasa z miesta FMFI UK, pavilón informatiky},
  year = {2021},
  url = {https://goo.gl/maps/aoSspK4jat9nE2Lc9},
  urldate = {2023-04-20}
}

@INPROCEEDINGS{sort,
  author={Bewley, Alex and Ge, Zongyuan and Ott, Lionel and Ramos, Fabio and Upcroft, Ben},
  booktitle={2016 IEEE International Conference on Image Processing (ICIP)}, 
  title={Simple online and realtime tracking}, 
  year={2016},
  volume={},
  number={},
  pages={3464-3468},
  doi={10.1109/ICIP.2016.7533003}
}

@misc{ocsort,
      title={Observation-Centric SORT: Rethinking SORT for Robust Multi-Object Tracking}, 
      author={Jinkun Cao and Jiangmiao Pang and Xinshuo Weng and Rawal Khirodkar and Kris Kitani},
      year={2023},
      eprint={2203.14360},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{deepsort,
      title={Simple Online and Realtime Tracking with a Deep Association Metric}, 
      author={Nicolai Wojke and Alex Bewley and Dietrich Paulus},
      year={2017},
      eprint={1703.07402},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{bytetrack,
      title={ByteTrack: Multi-Object Tracking by Associating Every Detection Box}, 
      author={Yifu Zhang and Peize Sun and Yi Jiang and Dongdong Yu and Fucheng Weng and Zehuan Yuan and Ping Luo and Wenyu Liu and Xinggang Wang},
      year={2022},
      eprint={2110.06864},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}


@misc{strongsort,
      title={StrongSORT: Make DeepSORT Great Again}, 
      author={Yunhao Du and Zhicheng Zhao and Yang Song and Yanyun Zhao and Fei Su and Tao Gong and Hongying Meng},
      year={2023},
      eprint={2202.13514},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{alex,
author = {Llamas, Jose and Lerones, Pedro and Medina, Roberto and Zalama, Eduardo and Gómez-García-Bermejo, Jaime},
year = {2017},
month = {09},
pages = {992},
title = {Classification of Architectural Heritage Images Using Deep Learning Techniques},
volume = {7},
journal = {Applied Sciences},
doi = {10.3390/app7100992}
}

@article{APA,
issn = {1524-9050},
journal = {IEEE transactions on intelligent transportation systems},
pages = {2146--2154},
volume = {21},
publisher = {IEEE},
number = {5},
year = {2020},
title = {How Do Drivers Allocate Their Potential Attention? Driving Fixation Prediction via Convolutional Neural Networks},
language = {eng},
author = {Deng, Tao and Yan, Hongmei and Qin, Long and Ngo, Thuyen and Manjunath, B. S},
keywords = {Automobiles ; convolutional neural networks ; Data models ; eye tracking ; Fixation prediction ; Gaze tracking ; Predictive models ; traffic driving ; Videos ; visual attention ; Visualization},
}

@misc{simonyan2015deep,
      title={Very Deep Convolutional Networks for Large-Scale Image Recognition}, 
      author={Karen Simonyan and Andrew Zisserman},
      year={2015},
      eprint={1409.1556},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{criticalpoint,
author = {Jayawardana, Rahul and Bandaranayake, Thusitha},
year = {2021},
month = {04},
pages = {},
title = {ANALYSIS OF OPTIMIZING NEURAL NETWORKS AND ARTIFICIAL INTELLIGENT MODELS FOR GUIDANCE, CONTROL, AND NAVIGATION SYSTEMS}
}

@article{bp,
  title={Learning representations by back-propagating errors},
  author={David E. Rumelhart and Geoffrey E. Hinton and Ronald J. Williams},
  journal={Nature},
  year={1986},
  volume={323},
  pages={533-536}
}

@book{Goodfellow-et-al-2016,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    year={2016}
}

@inproceedings{imagenet,
        AUTHOR = {Deng, J. and Dong, W. and Socher, R. and Li, L.-J. and Li, K. and Fei-Fei, L.},
        TITLE = {{ImageNet: A Large-Scale Hierarchical Image Database}},
        BOOKTITLE = {CVPR09},
        YEAR = {2009},
        BIBSOURCE = "http://www.image-net.org/papers/imagenet_cvpr09.bib"
}

@article{yellappan2016exposure,
  title={Exposure and perception on distraction towards roadside digital advertisements},
  author={Yellappan, Kaviyarasu and Ghani, Yusof and Musa, Maslina and Siam, MF and Tan, CY},
  year={2016}
}

@article{smiley2005traffic,
  title={Traffic safety evaluation of video advertising signs},
  author={Smiley, Alison and Persaud, Bhagwant and Bahar, Geni and Mollett, Calvin and Lyon, Craig and Smahel, Thomas and Kelman, W Leslie},
  journal={Transportation research record},
  volume={1937},
  number={1},
  pages={105--112},
  year={2005},
  publisher={SAGE Publications Sage CA: Los Angeles, CA}
}



% 02 - THEORY

@article{sigmoid,
  abstract = {{In this paper we demonstrate that finite linear combinations of compositions of a fixed, univariate function and a set of affine functionals can uniformly approximate any continuous function of n real variables with support in the unit hypercube; only mild conditions are imposed on the univariate function. Our results settle an open question about representability in the class of single hidden layer neural networks. In particular, we show that arbitrary decision regions can be arbitrarily well approximated by continuous feedforward neural networks with only a single internal, hidden layer and any continuous sigmoidal nonlinearity. The paper discusses approximation properties of other possible types of nonlinearities that might be implemented by artificial neural networks.}},
  added-at = {2012-03-02T03:39:18.000+0100},
  author = {Cybenko, G.},
  biburl = {https://www.bibsonomy.org/bibtex/2be85c56ae384216b2e35bdf79b7fb477/baby9992006},
  citeulike-article-id = {3561150},
  citeulike-linkout-0 = {http://dx.doi.org/10.1007/BF02551274},
  citeulike-linkout-1 = {http://www.springerlink.com/content/n873j15736072427},
  day = 1,
  doi = {10.1007/BF02551274},
  interhash = {96aecb02daa11041489259a8edb54070},
  intrahash = {be85c56ae384216b2e35bdf79b7fb477},
  issn = {0932-4194},
  journal = {Mathematics of Control, Signals, and Systems (MCSS)},
  keywords = {approximation, control, duckling, free, lunch, no, theorem, theory, ugly, universal},
  month = dec,
  number = 4,
  pages = {303--314},
  posted-at = {2012-02-28 13:17:08},
  priority = {2},
  publisher = {Springer London},
  timestamp = {2012-03-02T03:39:20.000+0100},
  title = {{Approximation by superpositions of a sigmoidal function}},
  url = {http://dx.doi.org/10.1007/BF02551274},
  volume = 2,
  year = 1989
}

@inproceedings{relu,
  added-at = {2022-06-07T12:08:40.000+0200},
  author = {Nair, Vinod and Hinton, Geoffrey E},
  biburl = {https://www.bibsonomy.org/bibtex/2a0b7deb2839b69a52fcfcc15b7277a2a/georgheyer},
  booktitle = {ICML 2010},
  interhash = {acefcb0a5d1a937232f02f3fe0d5ab86},
  intrahash = {a0b7deb2839b69a52fcfcc15b7277a2a},
  keywords = {},
  pages = {807--814},
  timestamp = {2022-06-07T12:08:40.000+0200},
  title = {Rectified linear units improve restricted boltzmann machines},
  year = 2010
}

@inproceedings{prelu,
issn = {2380-7504},
pages = {1026--1034},
publisher = {IEEE},
booktitle = {2015 IEEE International Conference on Computer Vision (ICCV)},
isbn = {1467383910},
year = {2015},
title = {Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification},
language = {eng},
author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
keywords = {Activation ; Adaptation models ; Biological neural networks ; Classification ; Computational efficiency ; Computational modeling ; Computer vision ; Conferences ; Gaussian distribution ; Image classification ; Neural networks ; Rectifiers ; Testing ; Training},
}





@inproceedings{TetkoIgorV2019ABOf,
series = {Lecture Notes in Computer Science},
issn = {0302-9743},
abstract = {Hyperparameter optimization of a neural network is a non-trivial task. It is time-consuming to evaluate a hyperparameter setting, no analytical expression of the impact of the hyperparameters are available, and the evaluations are noisy in the sense that the result is dependent on the training process and weight initialization. Bayesian optimization is a powerful tool to handle these problems. However, hyperparameter optimization of neural networks poses additional challenges, since the hyperparameters can be integer-valued, categorical, and/or conditional, whereas Bayesian optimization often assumes variables to be real-valued. In this paper we present an architecture-aware transformation of neural networks applied in the kernel of a Gaussian process to boost the performance of hyperparameter optimization.
The empirical experiment in this paper demonstrates that by introducing an architecture-aware transformation of the kernel, the performance of the Bayesian optimizer shows a clear improvement over a naïve implementation and that the results are comparable to other state-of-the-art methods.},
pages = {220--231},
volume = {11728},
publisher = {Springer International Publishing AG},
booktitle = {Artificial Neural Networks and Machine Learning - ICANN 2019: Deep Learning},
isbn = {3030304833},
year = {2019},
title = {Architecture-Aware Bayesian Optimization for Neural Network Tuning},
copyright = {Springer Nature Switzerland AG 2019},
language = {eng},
address = {Switzerland},
author = {Tetko, Igor V and Kůrková, Věra and Karpov, Pavel and Theis, Fabian},
keywords = {Gaussian process ; Hyperparameter optimization ; Neural networks ; Transformation},
}


@article{DettmersTim2019SNfS,
issn = {2331-8422},
journal = {arXiv.org},
publisher = {Cornell University Library, arXiv.org},
year = {2019},
title = {Sparse Networks from Scratch: Faster Training without Losing Performance},
copyright = {2019. This work is published under http://arxiv.org/licenses/nonexclusive-distrib/1.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License.},
language = {eng},
address = {Ithaca},
author = {Dettmers, Tim and Zettlemoyer, Luke},
keywords = {Algorithms ; Error reduction ; Learning ; Momentum ; Neural networks ; Training},
}


@book{zhang2020dive,
title={Dive into Deep Learning},
author={Aston Zhang and Zachary C. Lipton and Mu Li and Alexander J. Smola},
note={\url{https://d2l.ai}},
year={2020}
}

@Inbook{Shanmuganathan2016,
author="Shanmuganathan, Subana",
editor="Shanmuganathan, Subana
and Samarasinghe, Sandhya",
title="Artificial Neural Network Modelling: An Introduction",
bookTitle="Artificial Neural Network Modelling",
year="2016",
publisher="Springer International Publishing",
address="Cham",
pages="1--14",
abstract="While scientists from different disciplines, such as neuroscience, medicine and high performance computing, eagerly attempt to understand how the human brain functioning happens, Knowledge Engineers in computing have been successful in making use of the brain models thus far discovered to introduce heuristics into computational algorithmic modelling. Gaining further understanding on human brain/nerve cell anatomy, structure, and how the human brain functions, is described to be significant especially, to devise treatments for presently described as incurable brain and nervous system related diseases, such as Alzheimer's and epilepsy. Despite some major breakthroughs seen over the last few decades neuroanatomists and neurobiologists of the medical world are yet to understand how we humans think, learn and remember, and how our cognition and behaviour are linked. In this context, the chapter outlines the most recent human brain research initiatives following which early Artificial Neural Network (ANN) architectures, components, related terms and hybrids are elaborated.",
isbn="978-3-319-28495-8",
doi="10.1007/978-3-319-28495-8_1",
url="https://doi.org/10.1007/978-3-319-28495-8_1"
}

@book{RosinPaulL2019RIAa,
series = {Advances in Computer Vision and Pattern Recognition},
abstract = {This book focuses on the fundamentals and recent advances in RGB-D imaging as well as covering a range of RGB-D applications. The topics covered include: data acquisition, data quality assessment, filling holes, 3D reconstruction, SLAM, multiple depth camera systems, segmentation, object detection, salience detection, pose estimation, geometric modelling, fall detection, autonomous driving, motor rehabilitation therapy, people counting and cognitive service robots.
The availability of cheap RGB-D sensors has led to an explosion over the last five years in the capture and application of colour plus depth data. The addition of depth data to regular RGB images vastly increases the range of applications, and has resulted in a demand for robust and real-time processing of RGB-D data. There remain many technical challenges, and RGB-D image processing is an ongoing research area. This book covers the full state of the art, and consists of a series of chapters by internationally renowned experts in the field. Each chapter is written so as to provide a detailed overview of that topic. RGB-D Image Analysis and Processing will enable both students and professional developers alike to quickly get up to speed with contemporary techniques, and apply RGB-D imaging in their own projects.},
publisher = {Springer International Publishing AG},
isbn = {9783030286026},
year = {2019},
title = {RGB-D Image Analysis and Processing},
language = {eng},
address = {Cham},
author = {Rosin, Paul L and Lai, Yu-Kun and Shao, Ling and Liu, Yonghuai},
keywords = {Image analysis ; Image processing},
}

@article{loss,
  title={On loss functions for deep neural networks in classification},
  author={Janocha, Katarzyna and Czarnecki, Wojciech Marian},
  journal={arXiv preprint arXiv:1702.05659},
  year={2017}
}

@INPROCEEDINGS{cnn-intro,
  author={Dai, Dengyuhan},
  booktitle={2021 International Conference on Big Data, Artificial Intelligence and Risk Management (ICBAR)}, 
  title={An Introduction of CNN: Models and Training on Neural Network Models}, 
  year={2021},
  volume={},
  number={},
  pages={135-138},
  doi={10.1109/ICBAR55169.2021.00037}
}

@ARTICLE{lenet,  author={Lecun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.},  journal={Proceedings of the IEEE},   title={Gradient-based learning applied to document recognition},   year={1998},  volume={86},  number={11},  pages={2278-2324},  doi={10.1109/5.726791}}

@misc{ilsvrc,
  title = {Large Scale Visual Recognition Challenge 2012 (ILSVRC2012)},
  howpublished = {\url{https://www.image-net.org/challenges/LSVRC/2012/results.html}},
  note = {urldate: 2022-10-04}
}

@incollection{AlexNet,
  author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
  biburl = {https://www.bibsonomy.org/bibtex/2886c491fe45049fee3c9660df30bb5c4/albinzehe},
  booktitle = {Advances in Neural Information Processing Systems 25},
  editor = {Pereira, F. and Burges, C. J. C. and Bottou, L. and Weinberger, K. Q.},
  interhash = {74bbb5dea5afb1b088bd10e317f1f0d2},
  keywords = {cnn deeplearning ma-zehe neuralnet},
  pages = {1097--1105},
  publisher = {Curran Associates, Inc.},
  title = {ImageNet Classification with Deep Convolutional Neural Networks},
  year = 2012
}

@INBOOK{7547482,  author={Keller, James M. and Liu, Derong and Fogel, David B.},  booktitle={Fundamentals of Computational Intelligence: Neural Networks, Fuzzy Systems, and Evolutionary Computation},   title={Introduction and Single-Layer Neural Networks},   year={2016},  volume={},  number={},  pages={5-34},  doi={}
}

@online{tobii,
  title = {Tobii Pro Glasses 3},
  year = {2023},
  url = {https://www.tobii.com/products/eye-trackers/wearables/tobii-pro-glasses-3},
  urldate = {2023-04-25}
}

@online{yolov8,
  title = {Ultralytics YOLOv8},
  year = {2023},
  autor={Glenn Jocher},
  url = {https://github.com/ultralytics/ultralytics},
  urldate = {2023-04-25}
}

@online{v7,
  title = {V7 The AI Data Engine},
  year = {2023},
  url = {https://www.v7labs.com/},
  urldate = {2023-04-25}
}

@article{clear,
issn = {1687-5176},
journal = {EURASIP journal on image and video processing},
pages = {1--10},
volume = {2008},
publisher = {Springer International Publishing},
number = {1},
year = {2008},
title = {Evaluating Multiple Object Tracking Performance: The CLEAR MOT Metrics},
copyright = {K. Bernardin and R. Stiefelhagen. 2008. This article is published under license to BioMed Central Ltd. This is an open access article distributed under the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.},
language = {eng},
address = {Cham},
author = {Bernardin, Keni and Stiefelhagen, Rainer},
keywords = {Biometrics ; Engineering ; Image Processing and Computer Vision ; Pattern Recognition ; Research Article ; Signal,Image and Speech Processing ; Video Tracking in Complex Scenes for Surveillance Applications},
}


@article{vace,
issn = {0162-8828},
pages = {319--336},
volume = {31},
publisher = {IEEE},
number = {2},
year = {2009},
title = {Framework for Performance Evaluation of Face, Text, and Vehicle Detection and Tracking in Video: Data, Metrics, and Protocol},
copyright = {2009 INIST-CNRS},
language = {eng},
address = {Los Alamitos, CA},
author = {Kasturi, R. and Goldgof, D. and Soundararajan, P. and Manohar, V. and Garofolo, J. and Bowers, R. and Boonstra, M. and Korzhova, V. and Jing Zhang}
}

@article{idf,
issn = {2331-8422},
abstract = {To help accelerate progress in multi-target, multi-camera tracking systems, we present (i) a new pair of precision-recall measures of performance that treats errors of all types uniformly and emphasizes correct identification over sources of error; (ii) the largest fully-annotated and calibrated data set to date with more than 2 million frames of 1080p, 60fps video taken by 8 cameras observing more than 2,700 identities over 85 minutes; and (iii) a reference software system as a comparison baseline. We show that (i) our measures properly account for bottom-line identity match performance in the multi-camera setting; (ii) our data set poses realistic challenges to current trackers; and (iii) the performance of our system is comparable to the state of the art.},
journal = {arXiv.org},
publisher = {Cornell University Library, arXiv.org},
year = {2016},
title = {Performance Measures and a Data Set for Multi-Target, Multi-Camera Tracking},
copyright = {2016. This work is published under http://creativecommons.org/licenses/by-nc-sa/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License.},
language = {eng},
address = {Ithaca},
author = {Ristani, Ergys and Solera, Francesco and Zou, Roger S and Cucchiara, Rita and Tomasi, Carlo},
keywords = {Datasets ; Error correction ; Multiple target tracking ; Tracking systems},
}


@article{mota,
issn = {1687-5176},
abstract = {Simultaneous tracking of multiple persons in real-world environments is an active research field and several approaches have been proposed, based on a variety of features and algorithms. Recently, there has been a growing interest in organizing systematic evaluations to compare the various techniques. Unfortunately, the lack of common metrics for measuring the performance of multiple object trackers still makes it hard to compare their results. In this work, we introduce two intuitive and general metrics to allow for objective comparison of tracker characteristics, focusing on their precision in estimating object locations, their accuracy in recognizing object configurations and their ability to consistently label objects over time. These metrics have been extensively used in two large-scale international evaluations, the 2006 and 2007 CLEAR evaluations, to measure and compare the performance of multiple object trackers for a wide variety of tracking tasks. Selected performance results are presented and the advantages and drawbacks of the presented metrics are discussed based on the experience gained during the evaluations.},
journal = {EURASIP journal on image and video processing},
pages = {1--10},
volume = {2008},
publisher = {Springer International Publishing},
number = {1},
year = {2008},
title = {Evaluating Multiple Object Tracking Performance: The CLEAR MOT Metrics},
copyright = {K. Bernardin and R. Stiefelhagen. 2008. This article is published under license to BioMed Central Ltd. This is an open access article distributed under the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.},
language = {eng},
address = {Cham},
author = {Bernardin, Keni and Stiefelhagen, Rainer},
keywords = {Biometrics ; Engineering ; Image Processing and Computer Vision ; Pattern Recognition ; Research Article ; Signal,Image and Speech Processing ; Video Tracking in Complex Scenes for Surveillance Applications},
}



@article{hota,
  author       = {Jonathon Luiten and
                  Aljosa Osep and
                  Patrick Dendorfer and
                  Philip H. S. Torr and
                  Andreas Geiger and
                  Laura Leal{-}Taix{\'{e}} and
                  Bastian Leibe},
  title        = {{HOTA:} {A} Higher Order Metric for Evaluating Multi-Object Tracking},
  journal      = {CoRR},
  volume       = {abs/2009.07736},
  year         = {2020},
  url          = {https://arxiv.org/abs/2009.07736},
  eprinttype    = {arXiv},
  eprint       = {2009.07736},
  timestamp    = {Fri, 20 Nov 2020 13:22:19 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2009-07736.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}